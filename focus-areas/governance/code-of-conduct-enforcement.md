# Focus Area: Resource Page

## Disclaimer / Caveats

**This is a work in process document being used to gather feedback and may not yet represent the views of the CHAOSS project.**

Please feel free to contribute,  by improving this document.

## Question

**Question:** Is enforcement process running at scale ?(trust, volume, responsiveness, accuracy, fairness ...) 


## 1. Description

This section provides a rationale for why this question is important to diversity and inclusion. Example for how to use this template: Documentation


## 2. Sample Objectives

- A project or event participant wants to be clear about reporting processes before participating.
- A project or event participant wants to be clear about WHO will handle reports, as prerequisite for feeling safe reporting.
- Someone who has been reported understand what to expect in the investigative process.
- Both reporter and reported want to understand the potential consequences to the reported.
- Both reporter and reported understand what information is required, and which is optional.
- Both reporter and reported want to understand the milestones of an investigation, and when to expect updates and outcome.
- Potential reporters want to understand if and how anonymous reports are taken, and addressed.
- Both reporter and reported want to understand who will see their report, and how their data is handled.
- Both reporter and reporter, want to know if he project / event is serious about enforcement. Perhaps How reports have been handled in the past.
- Reporting guidelines describe proxy reporting.



## 3. Sample Strategies

‘How to Report’ is easily discoverable  (linked from Code of Conduct)

- Investigation process and recommendations-generation are documented
  - Are not done by only one person and ideally not by people invested in the process (not a default i.e. project lead).
  - Include policies for handling data.
  - Are consultive of areas of the project or event, which through no fault of their own ,may be impacted by the report, or the outcome of the report.  
- Decision making
  - Ideally done via RASCI of stakeholders or similar consultative method to avoid the ;’why wasn’t I consulted’.
  - ...yet limits the number of people involved.
  - Considers legal implications for decision makers.  
- Reporting is accepted in local languages (and translated).
 Consequences
 - Includes multiple possible responses that include short- and long-term consequences
 - Escalating or proportionate consequences based on the scope, impact, and frequency of the incident.
 - Description of how people are ‘brought back into the project after a short-term ban.  Including limitations and consultation with those impacted.
 - Includes escalation where past reports exist, or if further actions occur (Many projects use consequence ladders to create visibility for escalation)
 - Includes descriptions of limitations for interactions with reporter, and others involved.
 - Consider private and public statements.
- Triage processes prioritize according to a set of rules
  - Employment laws (if staff involved)
  - Risk area (legal, immediate physical risk/emergency, anonymous)
  - Report type (unwanted sexual attention, disruptive behavior)
  - Priority (p1, p2, p3, p4 etc)
  - Consider past events./reports
  - Divert reports unrelated to CoC violations to appropriate audience/leadership.
- Enforcement Reporting data
  - Considers local laws for privacy, reporting, hotline, privacy and GDPR
  - Has a data policy that describes how data is stored, who has access, and how access is updated, when someone leaves, or is added that process.
  - Is centralized to ensure that bad actors, are recognized when they turn up in other parts of the project/events.
- Communication
  - With reporter and reported (even when anonymous) are predictable, and regular until final decision/action.
  - Include all impacted by the process.
  - Include follow-up after decisions, to check on well-being  and experiences of reported.
  - Efficiency (invested time, funds, human resources)
  - Process checklists are followed.
  - More...


## 4. Sample Success Metrics
_Qualitative(hypothesis mostly)_

Number of reports (at first) increases .   (trust metric)
Number of reports peaks (over time) (stability metric ?)
Number of reports declines (after peak)  (community health improvements?)
Number of underrepresented people reporting (shows trust)
Time spent on enforcement (resource, efficiency,  financial metric) declines over time


_Quantitative_

-Reporter sentiment for trust, effectiveness and quality of outcome.
All decision makers, and consulted sentiment for trust, use of their time and quality of outcome.
Reported sentiment for clear process. (they won’t always like outcome, that;s expected)
Project or event sentiment for enforcement is rated as high and improves





## 5. Resources

- [Mozilla Community Participation Guidelines Workflow](https://medium.com/mozilla-open-innovation/how-were-making-code-of-conduct-enforcement-real-and-scaling-it-3e382cf94415)
- [Mozilla Triage Rulesd](https://docs.google.com/document/d/1rQoxKgOBkH1WfC4bDcXq_0y5MK7RWbbeDk4uqNjQMBc/edit#heading=h.q1sovk9pfdka)
